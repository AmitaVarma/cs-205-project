{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O6BHM37MzZ_5"
   },
   "source": [
    "# 0. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g2cLo1ys12xZ",
    "outputId": "c2736c14-f313-4ef6-9916-3f8533a7be54"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function format_img_and_label at 0x7f11e4fc1268> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Unable to locate the source code of <function format_img_and_label at 0x7f11e4fc1268>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function format_img_and_label at 0x7f11e4fc1268> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Unable to locate the source code of <function format_img_and_label at 0x7f11e4fc1268>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "mobilenet_1.00_224 (Function (None, 1, 1, 1024)        3228864   \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               262400    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 15)                975       \n",
      "=================================================================\n",
      "Total params: 3,508,687\n",
      "Trainable params: 3,486,799\n",
      "Non-trainable params: 21,888\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "221/221 [==============================] - 223s 979ms/step - loss: 0.7611 - accuracy: 0.1477 - val_loss: 0.5662 - val_accuracy: 0.2376\n",
      "Epoch 2/5\n",
      "221/221 [==============================] - 218s 985ms/step - loss: 0.2637 - accuracy: 0.4678 - val_loss: 0.2789 - val_accuracy: 0.4678\n",
      "Epoch 3/5\n",
      "221/221 [==============================] - 208s 942ms/step - loss: 0.2025 - accuracy: 0.5756 - val_loss: 0.2419 - val_accuracy: 0.4881\n",
      "Epoch 4/5\n",
      "221/221 [==============================] - 186s 841ms/step - loss: 0.1737 - accuracy: 0.6103 - val_loss: 0.2387 - val_accuracy: 0.4876\n",
      "Epoch 5/5\n",
      "221/221 [==============================] - 175s 792ms/step - loss: 0.1504 - accuracy: 0.6496 - val_loss: 0.2384 - val_accuracy: 0.4904\n",
      "CPU times: user 14min 2s, sys: 46.5 s, total: 14min 48s\n",
      "Wall time: 16min 57s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.compat.v1.keras.applications import MobileNet\n",
    "from tensorflow.compat.v1.keras import layers\n",
    "from tensorflow.compat.v1.keras.optimizers import Adam, RMSprop\n",
    "from tensorflow.compat.v1.keras.metrics import binary_crossentropy\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import io\n",
    "import os\n",
    "import yaml\n",
    "from datetime import datetime\n",
    "import boto3\n",
    "import s3fs\n",
    "\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "\n",
    "# you will need to create your own aws credentials to access S3\n",
    "creds = yaml.safe_load(open('aws_credentials.yml'))\n",
    "AWS_ACCESS_KEY = creds['aws_access_key_id']\n",
    "AWS_SECRET_ACCESS_KEY = creds['aws_secret_key_id']\n",
    "BUCKET_NAME = 'cs205-project-xray'\n",
    "S3_DIRECTORY = 's3://' + BUCKET_NAME\n",
    "\n",
    "HEIGHT = 32 #256\n",
    "WIDTH = 32 #256\n",
    "BATCH_SIZE = 32\n",
    "BUFFER_SIZE = 64\n",
    "\n",
    "# connect to AWS S3\n",
    "s3_resource = boto3.resource('s3',\n",
    "                             aws_access_key_id=AWS_ACCESS_KEY,\n",
    "                             aws_secret_access_key=AWS_SECRET_ACCESS_KEY)\n",
    "\n",
    "my_bucket = s3_resource.Bucket(name=BUCKET_NAME)\n",
    "\n",
    "\n",
    "\n",
    "###\n",
    "# Helper functions to create data set\n",
    "# - modified from Ashref Maiza's code in the link below \n",
    "# - link: https://towardsdatascience.com/multi-label-image-classification-in-tensorflow-2-0-7d4cf8a4bc72\n",
    "###\n",
    "\n",
    "def format_img_and_label(im_file, lab):\n",
    "    img_dir = S3_DIRECTORY + '/images/' + im_file\n",
    "    # read in image tensor\n",
    "    img_str = tf.io.read_file(img_dir)   \n",
    "    # decode image\n",
    "    img_decoded = tf.image.decode_png(img_str, channels=3)\n",
    "    # resize image to fixed shape\n",
    "    resized_img = tf.image.resize(img_decoded, [HEIGHT, WIDTH])\n",
    "    # normalize image\n",
    "    normalized_img = resized_img / 255.0\n",
    "    return normalized_img, lab\n",
    "\n",
    "\n",
    "def create_dataset(filenames, labels):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((filenames, labels))\n",
    "    dataset = dataset.map(format_img_and_label, num_parallel_calls=AUTOTUNE)\n",
    "    return dataset\n",
    "\n",
    "\n",
    "# fetch links to image files from S3\n",
    "loaded_imgs = []\n",
    "\n",
    "for image_file in my_bucket.objects.filter(Prefix='images').limit(8840):\n",
    "    loaded_imgs.append(image_file.key[7:])\n",
    "\n",
    "    \n",
    "# load image labels\n",
    "df = pd.read_csv('s3://cs205-project-xray/Data_Entry_2017_v2020.csv')\n",
    "df = df[df['Image Index'].isin(loaded_imgs)].copy()\n",
    "img_and_label = df[[\"Image Index\", \"Finding Labels\"]].copy()\n",
    "img_and_label['Finding Labels'] = img_and_label['Finding Labels'].str.split('|')\n",
    "\n",
    "# create data sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(img_and_label['Image Index'], \n",
    "                                                  img_and_label['Finding Labels'], \n",
    "                                                  test_size=0.2)\n",
    "\n",
    "X_train = list(X_train)\n",
    "X_test = list(X_test)\n",
    "y_train = list(y_train)\n",
    "y_test = list(y_test)\n",
    "\n",
    "\n",
    "MLB = MultiLabelBinarizer()\n",
    "MLB.fit(y_test)\n",
    "\n",
    "# multi-label binary transform our labels\n",
    "y_train = MLB.transform(y_train)\n",
    "y_test = MLB.transform(y_test)\n",
    "\n",
    "train_data = create_dataset(X_train, y_train)\n",
    "test_data = create_dataset(X_test, y_test)\n",
    "\n",
    "\n",
    "# model building and training\n",
    "cnn_base = MobileNet(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "  cnn_base,\n",
    "  layers.Flatten(),\n",
    "  layers.Dense(256, activation='relu'),\n",
    "  layers.Dropout(0.1),\n",
    "  layers.Dense(64, activation='relu'),\n",
    "  # 15 labels to classify\n",
    "  layers.Dense(15, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# final number of parameters after adding on head layer to base MobileNet\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer=RMSprop(lr=2e-5),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "history = model.fit(train_data.batch(BATCH_SIZE).prefetch(buffer_size=AUTOTUNE),\n",
    "                    validation_data=test_data.batch(BATCH_SIZE).prefetch(buffer_size=AUTOTUNE),\n",
    "                    epochs=5)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "sun.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
